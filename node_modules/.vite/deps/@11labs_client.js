// node_modules/@11labs/client/dist/lib.modern.js
function t() {
  return t = Object.assign ? Object.assign.bind() : function(t2) {
    for (var e2 = 1; e2 < arguments.length; e2++) {
      var n2 = arguments[e2];
      for (var s2 in n2) ({}).hasOwnProperty.call(n2, s2) && (t2[s2] = n2[s2]);
    }
    return t2;
  }, t.apply(null, arguments);
}
function e(t2) {
  const e2 = new Uint8Array(t2);
  return window.btoa(String.fromCharCode(...e2));
}
function n(t2) {
  const e2 = window.atob(t2), n2 = e2.length, s2 = new Uint8Array(n2);
  for (let t3 = 0; t3 < n2; t3++) s2[t3] = e2.charCodeAt(t3);
  return s2.buffer;
}
var s = new Blob([`
      const TARGET_SAMPLE_RATE = 16000;
      class RawAudioProcessor extends AudioWorkletProcessor {
        constructor() {
          super();
          this.buffer = []; // Initialize an empty buffer
          this.bufferSize = TARGET_SAMPLE_RATE / 4; // Define the threshold for buffer size to be ~0.25s

          if (globalThis.LibSampleRate && sampleRate !== TARGET_SAMPLE_RATE) {
            globalThis.LibSampleRate.create(1, sampleRate, TARGET_SAMPLE_RATE).then(resampler => {
              this.resampler = resampler;
            });
          }
        }
        process(inputs, outputs) {
          const input = inputs[0]; // Get the first input node
          if (input.length > 0) {
            let channelData = input[0]; // Get the first channel's data

            // Resample the audio if necessary
            if (this.resampler) {
              channelData = this.resampler.full(channelData);
            }

            // Add channel data to the buffer
            this.buffer.push(...channelData);
            // Get max volume 
            let sum = 0.0;
            for (let i = 0; i < channelData.length; i++) {
              sum += channelData[i] * channelData[i];
            }
            const maxVolume = Math.sqrt(sum / channelData.length);
            // Check if buffer size has reached or exceeded the threshold
            if (this.buffer.length >= this.bufferSize) {
              const float32Array = new Float32Array(this.buffer)
              let pcm16Array = new Int16Array(float32Array.length);

              // Iterate through the Float32Array and convert each sample to PCM16
              for (let i = 0; i < float32Array.length; i++) {
                // Clamp the value to the range [-1, 1]
                let sample = Math.max(-1, Math.min(1, float32Array[i]));
            
                // Scale the sample to the range [-32768, 32767] and store it in the Int16Array
                pcm16Array[i] = sample < 0 ? sample * 32768 : sample * 32767;
              }
            
              // Send the buffered data to the main script
              this.port.postMessage([pcm16Array, maxVolume]);
            
              // Clear the buffer after sending
              this.buffer = [];
            }
          }
          return true; // Continue processing
        }
      }
      registerProcessor("raw-audio-processor", RawAudioProcessor);
  `], { type: "application/javascript" });
var o = URL.createObjectURL(s);
var a = class _a {
  static async create(t2) {
    let e2 = null, n2 = null;
    try {
      const s3 = navigator.mediaDevices.getSupportedConstraints().sampleRate;
      e2 = new window.AudioContext(s3 ? { sampleRate: t2 } : {});
      const i3 = e2.createAnalyser();
      s3 || await e2.audioWorklet.addModule("https://cdn.jsdelivr.net/npm/@alexanderolsen/libsamplerate-js@2.1.2/dist/libsamplerate.worklet.js"), await e2.audioWorklet.addModule(o), n2 = await navigator.mediaDevices.getUserMedia({ audio: { sampleRate: { ideal: t2 }, echoCancellation: { ideal: true }, noiseSuppression: { ideal: true } } });
      const r2 = e2.createMediaStreamSource(n2), l2 = new AudioWorkletNode(e2, "raw-audio-processor");
      return r2.connect(i3), i3.connect(l2), new _a(e2, i3, l2, n2);
    } catch (t3) {
      var s2, i2;
      throw null == (s2 = n2) || s2.getTracks().forEach((t4) => t4.stop()), null == (i2 = e2) || i2.close(), t3;
    }
  }
  constructor(t2, e2, n2, s2) {
    this.context = void 0, this.analyser = void 0, this.worklet = void 0, this.inputStream = void 0, this.context = t2, this.analyser = e2, this.worklet = n2, this.inputStream = s2;
  }
  async close() {
    this.inputStream.getTracks().forEach((t2) => t2.stop()), await this.context.close();
  }
};
var i = new Blob(['\n      class AudioConcatProcessor extends AudioWorkletProcessor {\n        constructor() {\n          super();\n          this.buffers = []; // Initialize an empty buffer\n          this.cursor = 0;\n          this.currentBuffer = null;\n          this.wasInterrupted = false;\n          this.finished = false;\n\n          this.port.onmessage = ({ data }) => {\n            switch (data.type) {\n              case "buffer":\n                this.wasInterrupted = false;\n                this.buffers.push(new Int16Array(data.buffer));\n                break;\n              case "interrupt":\n                this.wasInterrupted = true;\n                break;\n              case "clearInterrupted":\n                if (this.wasInterrupted) {\n                  this.wasInterrupted = false;\n                  this.buffers = [];\n                  this.currentBuffer = null;\n                }\n            }\n          };\n        }\n        process(_, outputs) {\n          let finished = false;\n          const output = outputs[0][0];\n          for (let i = 0; i < output.length; i++) {\n            if (!this.currentBuffer) {\n              if (this.buffers.length === 0) {\n                finished = true;\n                break;\n              }\n              this.currentBuffer = this.buffers.shift();\n              this.cursor = 0;\n            }\n\n            output[i] = this.currentBuffer[this.cursor] / 32768;\n            this.cursor++;\n\n            if (this.cursor >= this.currentBuffer.length) {\n              this.currentBuffer = null;\n            }\n          }\n\n          if (this.finished !== finished) {\n            this.finished = finished;\n            this.port.postMessage({ type: "process", finished });\n          }\n\n          return true; // Continue processing\n        }\n      }\n\n      registerProcessor("audio-concat-processor", AudioConcatProcessor);\n    '], { type: "application/javascript" });
var r = URL.createObjectURL(i);
var l = class _l {
  static async create(t2) {
    let e2 = null;
    try {
      e2 = new AudioContext({ sampleRate: t2 });
      const n3 = e2.createAnalyser(), s2 = e2.createGain();
      s2.connect(n3), n3.connect(e2.destination), await e2.audioWorklet.addModule(r);
      const o2 = new AudioWorkletNode(e2, "audio-concat-processor");
      return o2.connect(s2), new _l(e2, n3, s2, o2);
    } catch (t3) {
      var n2;
      throw null == (n2 = e2) || n2.close(), t3;
    }
  }
  constructor(t2, e2, n2, s2) {
    this.context = void 0, this.analyser = void 0, this.gain = void 0, this.worklet = void 0, this.context = t2, this.analyser = e2, this.gain = n2, this.worklet = s2;
  }
  async close() {
    await this.context.close();
  }
};
function c(t2) {
  return !!t2.type;
}
var u = class _u {
  static async create(t2) {
    let e2 = null;
    try {
      var n2;
      const s3 = null != (n2 = t2.origin) ? n2 : "wss://api.elevenlabs.io", o2 = t2.signedUrl ? t2.signedUrl : s3 + "/v1/convai/conversation?agent_id=" + t2.agentId, a2 = ["convai"];
      t2.authorization && a2.push(`bearer.${t2.authorization}`), e2 = new WebSocket(o2, a2);
      const i2 = await new Promise((n3, s4) => {
        e2.addEventListener("open", () => {
          var n4;
          const s5 = { type: "conversation_initiation_client_data" };
          var o3, a3, i3, r3;
          t2.overrides && (s5.conversation_config_override = { agent: { prompt: null == (o3 = t2.overrides.agent) ? void 0 : o3.prompt, first_message: null == (a3 = t2.overrides.agent) ? void 0 : a3.firstMessage, language: null == (i3 = t2.overrides.agent) ? void 0 : i3.language }, tts: { voice_id: null == (r3 = t2.overrides.tts) ? void 0 : r3.voiceId } }), t2.customLlmExtraBody && (s5.custom_llm_extra_body = t2.customLlmExtraBody), null == (n4 = e2) || n4.send(JSON.stringify(s5));
        }, { once: true }), e2.addEventListener("error", s4), e2.addEventListener("close", s4), e2.addEventListener("message", (t3) => {
          const e3 = JSON.parse(t3.data);
          c(e3) && ("conversation_initiation_metadata" === e3.type ? n3(e3.conversation_initiation_metadata_event) : console.warn("First received message is not conversation metadata."));
        }, { once: true });
      }), r2 = i2.conversation_id, l2 = parseInt(i2.agent_output_audio_format.replace("pcm_", ""));
      return new _u(e2, r2, l2);
    } catch (t3) {
      var s2;
      throw null == (s2 = e2) || s2.close(), t3;
    }
  }
  constructor(t2, e2, n2) {
    this.socket = void 0, this.conversationId = void 0, this.sampleRate = void 0, this.socket = t2, this.conversationId = e2, this.sampleRate = n2;
  }
  close() {
    this.socket.close();
  }
  sendMessage(t2) {
    this.socket.send(JSON.stringify(t2));
  }
};
var h = { clientTools: {} };
var d = { onConnect: () => {
}, onDebug: () => {
}, onDisconnect: () => {
}, onError: () => {
}, onMessage: () => {
}, onModeChange: () => {
}, onStatusChange: () => {
} };
var p = class _p {
  static async startSession(e2) {
    const n2 = t({}, h, d, e2);
    n2.onStatusChange({ status: "connecting" });
    let s2 = null, o2 = null, i2 = null;
    try {
      return s2 = await a.create(16e3), o2 = await u.create(e2), i2 = await l.create(o2.sampleRate), new _p(n2, o2, s2, i2);
    } catch (t2) {
      var r2, c2, f;
      throw n2.onStatusChange({ status: "disconnected" }), null == (r2 = o2) || r2.close(), await (null == (c2 = s2) ? void 0 : c2.close()), await (null == (f = i2) ? void 0 : f.close()), t2;
    }
  }
  constructor(t2, s2, o2, a2) {
    var i2 = this;
    this.options = void 0, this.connection = void 0, this.input = void 0, this.output = void 0, this.lastInterruptTimestamp = 0, this.mode = "listening", this.status = "connecting", this.inputFrequencyData = void 0, this.outputFrequencyData = void 0, this.volume = 1, this.endSession = async function() {
      "connected" === i2.status && (i2.updateStatus("disconnecting"), i2.connection.close(), await i2.input.close(), await i2.output.close(), i2.updateStatus("disconnected"));
    }, this.updateMode = (t3) => {
      t3 !== this.mode && (this.mode = t3, this.options.onModeChange({ mode: t3 }));
    }, this.updateStatus = (t3) => {
      t3 !== this.status && (this.status = t3, this.options.onStatusChange({ status: t3 }));
    }, this.onEvent = async function(t3) {
      try {
        const n2 = JSON.parse(t3.data);
        if (!c(n2)) return;
        switch (n2.type) {
          case "interruption":
            n2.interruption_event && (i2.lastInterruptTimestamp = n2.interruption_event.event_id), i2.fadeOutAudio();
            break;
          case "agent_response":
            i2.options.onMessage({ source: "ai", message: n2.agent_response_event.agent_response });
            break;
          case "user_transcript":
            i2.options.onMessage({ source: "user", message: n2.user_transcription_event.user_transcript });
            break;
          case "internal_tentative_agent_response":
            i2.options.onDebug({ type: "tentative_agent_response", response: n2.tentative_agent_response_internal_event.tentative_agent_response });
            break;
          case "client_tool_call":
            if (i2.options.clientTools.hasOwnProperty(n2.client_tool_call.tool_name)) {
              try {
                var e2;
                const t4 = null != (e2 = await i2.options.clientTools[n2.client_tool_call.tool_name](n2.client_tool_call.parameters)) ? e2 : "Client tool execution successful.";
                i2.connection.sendMessage({ type: "client_tool_result", tool_call_id: n2.client_tool_call.tool_call_id, result: t4, is_error: false });
              } catch (t4) {
                i2.onError("Client tool execution failed with following error: " + (null == t4 ? void 0 : t4.message), { clientToolName: n2.client_tool_call.tool_name }), i2.connection.sendMessage({ type: "client_tool_result", tool_call_id: n2.client_tool_call.tool_call_id, result: "Client tool execution failed: " + (null == t4 ? void 0 : t4.message), is_error: true });
              }
              break;
            }
            if (i2.options.onUnhandledClientToolCall) {
              i2.options.onUnhandledClientToolCall(n2.client_tool_call);
              break;
            }
            i2.onError(`Client tool with name ${n2.client_tool_call.tool_name} is not defined on client`, { clientToolName: n2.client_tool_call.tool_name }), i2.connection.sendMessage({ type: "client_tool_result", tool_call_id: n2.client_tool_call.tool_call_id, result: `Client tool with name ${n2.client_tool_call.tool_name} is not defined on client`, is_error: true });
            break;
          case "audio":
            i2.lastInterruptTimestamp <= n2.audio_event.event_id && (i2.addAudioBase64Chunk(n2.audio_event.audio_base_64), i2.updateMode("speaking"));
            break;
          case "ping":
            i2.connection.sendMessage({ type: "pong", event_id: n2.ping_event.event_id });
            break;
          default:
            i2.options.onDebug(n2);
        }
      } catch (e3) {
        return void i2.onError("Failed to parse event data", { event: t3 });
      }
    }, this.onInputWorkletMessage = (t3) => {
      "connected" === this.status && this.connection.sendMessage({ user_audio_chunk: e(t3.data[0].buffer) });
    }, this.onOutputWorkletMessage = ({ data: t3 }) => {
      "process" === t3.type && this.updateMode(t3.finished ? "listening" : "speaking");
    }, this.addAudioBase64Chunk = async function(t3) {
      i2.output.gain.gain.value = i2.volume, i2.output.worklet.port.postMessage({ type: "clearInterrupted" }), i2.output.worklet.port.postMessage({ type: "buffer", buffer: n(t3) });
    }, this.fadeOutAudio = async function() {
      i2.updateMode("listening"), i2.output.worklet.port.postMessage({ type: "interrupt" }), i2.output.gain.gain.exponentialRampToValueAtTime(1e-4, i2.output.context.currentTime + 2), setTimeout(() => {
        i2.output.gain.gain.value = i2.volume, i2.output.worklet.port.postMessage({ type: "clearInterrupted" });
      }, 2e3);
    }, this.onError = (t3, e2) => {
      console.error(t3, e2), this.options.onError(t3, e2);
    }, this.calculateVolume = (t3) => {
      if (0 === t3.length) return 0;
      let e2 = 0;
      for (let n2 = 0; n2 < t3.length; n2++) e2 += t3[n2] / 255;
      return e2 /= t3.length, e2 < 0 ? 0 : e2 > 1 ? 1 : e2;
    }, this.getId = () => this.connection.conversationId, this.setVolume = ({ volume: t3 }) => {
      this.volume = t3;
    }, this.getInputByteFrequencyData = () => (null != this.inputFrequencyData || (this.inputFrequencyData = new Uint8Array(this.input.analyser.frequencyBinCount)), this.input.analyser.getByteFrequencyData(this.inputFrequencyData), this.inputFrequencyData), this.getOutputByteFrequencyData = () => (null != this.outputFrequencyData || (this.outputFrequencyData = new Uint8Array(this.output.analyser.frequencyBinCount)), this.output.analyser.getByteFrequencyData(this.outputFrequencyData), this.outputFrequencyData), this.getInputVolume = () => this.calculateVolume(this.getInputByteFrequencyData()), this.getOutputVolume = () => this.calculateVolume(this.getOutputByteFrequencyData()), this.options = t2, this.connection = s2, this.input = o2, this.output = a2, this.options.onConnect({ conversationId: s2.conversationId }), this.connection.socket.addEventListener("message", (t3) => {
      this.onEvent(t3);
    }), this.connection.socket.addEventListener("error", (t3) => {
      this.updateStatus("disconnected"), this.onError("Socket error", t3);
    }), this.connection.socket.addEventListener("close", () => {
      this.updateStatus("disconnected"), this.options.onDisconnect();
    }), this.input.worklet.port.onmessage = this.onInputWorkletMessage, this.output.worklet.port.onmessage = this.onOutputWorkletMessage, this.updateStatus("connected");
  }
};
export {
  p as Conversation
};
//# sourceMappingURL=@11labs_client.js.map
